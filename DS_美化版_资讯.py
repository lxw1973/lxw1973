# ================== å¯¼å…¥ä¾èµ– ==================
import streamlit as st
import pandas as pd
import numpy as np
import os
import secrets
import string
import datetime
import logging
from pathlib import Path
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split
import joblib
from dateutil.parser import parse
import requests
from transformers import pipeline

# ================== å…¨å±€å¸¸é‡ ==================
# è‡ªå®šä¹‰CSSæ ·å¼
STYLE = """
<style>
/* åŸºç¡€ä¸»é¢˜è‰² */
:root {
    --primary: #2c3e50;
    --secondary: #3498db;
    --accent: #e74c3c;
    --background: #f8f9fa;
    --text: #2c3e50;
}

/* æ•´ä½“å¸ƒå±€ä¼˜åŒ– */
.main {
    background-color: var(--background);
}

/* æ ‡é¢˜æ ·å¼ */
.header {
    font-size: 2.2rem;
    color: var(--primary);
    text-align: center;
    margin: 1.5rem 0;
    padding-bottom: 0.5rem;
    border-bottom: 3px solid var(--secondary);
}

/* åˆ†ç±»å¡ç‰‡ä¼˜åŒ– */
.item-card {
    padding: 1.2rem;
    margin: 1rem 0;
    border-radius: 12px;
    background: white;
    box-shadow: 0 2px 8px rgba(0,0,0,0.08);
    transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
    border: none;
}

.item-card:hover {
    transform: translateY(-3px);
    box-shadow: 0 6px 16px rgba(0,0,0,0.12);
}

/* é“¾æ¥æŒ‰é’®æ ·å¼ */
.link-btn {
    color: var(--secondary) !important;
    font-weight: 500;
    transition: color 0.2s;
}

.link-btn:hover {
    color: var(--primary) !important;
}

/* å¾½ç« æ ·å¼ç»Ÿä¸€ */
.tutorial-badge {
    font-size: 0.75em;
    padding: 4px 12px;
    border-radius: 20px;
    margin-left: 8px;
}

.popularity-badge {
    background: linear-gradient(135deg, #ff6b6b, #ff8e53);
    color: white;
    font-size: 0.85em;
    padding: 4px 12px;
    border-radius: 20px;
}

/* ä¾§è¾¹æ ä¼˜åŒ– */
[data-testid="stSidebar"] {
    background: linear-gradient(195deg, #f8f9fa 0%, #e9ecef 100%);
    border-right: 1px solid #dee2e6;
}

/* è¾“å…¥æ¡†æ ·å¼ */
.stTextInput input {
    border-radius: 8px;
    border: 1px solid #dee2e6;
}

/* æŒ‰é’®æ ·å¼ */
.stButton>button {
    border-radius: 8px;
    background: var(--secondary);
    color: white;
    transition: all 0.2s;
}

.stButton>button:hover {
    opacity: 0.9;
    transform: translateY(-1px);
}

/* ç»Ÿè®¡å¡ç‰‡ */
.stMetric {
    background: white;
    border-radius: 12px;
    padding: 1.5rem;
    box-shadow: 0 2px 6px rgba(0,0,0,0.06);
}

/* å“åº”å¼ä¼˜åŒ– */
@media (max-width: 768px) {
    .item-card {
        padding: 1rem;
        margin: 0.8rem 0;
    }

    .header {
        font-size: 1.8rem;
    }

    [data-testid="stSidebar"] {
        width: 240px !important;
    }
}

/* å·¥å…·æç¤ºä¼˜åŒ– */
.tooltip .tooltiptext {
    width: 320px;
    background: rgba(255,255,240,0.98);
    box-shadow: 0 4px 12px rgba(0,0,0,0.12);
    border: 1px solid rgba(0,0,0,0.08);
    backdrop-filter: blur(4px);
}

/* æ¸å˜æ ‡é¢˜ */
.gradient-text {
    background: linear-gradient(45deg, #2c3e50, #3498db);
    -webkit-background-clip: text;
    background-clip: text;
    color: transparent;
    font-weight: 700;
}
/* æ–°å¢å·¥å…·æç¤ºæ ·å¼ */
.item-card {
    position: relative;
    cursor: pointer;
}

.item-card .tooltip {
    visibility: hidden;
    opacity: 0;
    position: absolute;
    z-index: 999;
    bottom: 125%;
    left: 50%;
    transform: translateX(-50%);
    background: rgba(255,255,240,0.98);
    color: #2c3e50;
    padding: 1rem;
    border-radius: 8px;
    box-shadow: 0 4px 12px rgba(0,0,0,0.12);
    border: 1px solid rgba(0,0,0,0.08);
    min-width: 280px;
    max-width: 400px;
    transition: all 0.3s cubic-bezier(0.68, -0.55, 0.27, 1.55);
}

.item-card:hover .tooltip {
    visibility: visible;
    opacity: 1;
    transform: translateX(-50%) translateY(-5px);
}

.tooltip-content {
    font-size: 0.9em;
    line-height: 1.6;
}

.tooltip h4 {
    margin: 0 0 8px 0;
    color: var(--secondary);
    font-size: 1.1em;
}

.tooltip .description {
    margin-bottom: 8px;
}

.tooltip .features {
    color: #666;
    font-size: 0.9em;
}
/* æ–°å¢çƒ­ç‚¹èµ„è®¯æ ·å¼ */
.news-ticker {
    background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
    border: 1px solid #e9ecef;
    border-radius: 12px;
    padding: 1rem;
    margin: 1rem 0;
    box-shadow: 0 4px 12px rgba(0,0,0,0.08);
    position: relative;
    overflow: hidden;
}

.news-marquee {
    display: flex;
    animation: scroll 25s linear infinite;
    gap: 2rem;
}

@keyframes scroll {
    0% { transform: translateX(100%); }
    100% { transform: translateX(-100%); }
}

.news-card {
    flex: 0 0 300px;
    background: white;
    border-radius: 8px;
    padding: 1rem;
    box-shadow: 0 2px 6px rgba(0,0,0,0.06);
    transition: transform 0.3s ease;
    border-left: 4px solid var(--secondary);
}

.news-card:hover {
    transform: translateY(-3px);
}

.news-title {
    font-weight: 600;
    color: var(--primary);
    margin-bottom: 0.5rem;
    display: -webkit-box;
    -webkit-line-clamp: 2;
    -webkit-box-orient: vertical;
    overflow: hidden;
}

.news-source {
    font-size: 0.8em;
    color: #666;
    margin-bottom: 0.5rem;
}

.news-snippet {
    font-size: 0.9em;
    color: #666;
    line-height: 1.4;
    display: -webkit-box;
    -webkit-line-clamp: 3;
    -webkit-box-orient: vertical;
    overflow: hidden;
}

.news-time {
    font-size: 0.8em;
    color: #999;
    margin-top: 0.5rem;
}
</style>
"""


# å›½å®¶ä¸å›½æ——æ˜ å°„
COUNTRY_FLAGS = {
    'ç¾å›½': 'ğŸ‡ºğŸ‡¸', 'ä¸­å›½': 'ğŸ‡¨ğŸ‡³', 'æ³•å›½': 'ğŸ‡«ğŸ‡·', 'ä»¥è‰²åˆ—': 'ğŸ‡®ğŸ‡±',
    'è‹±å›½': 'ğŸ‡¬ğŸ‡§', 'åŠ æ‹¿å¤§': 'ğŸ‡¨ğŸ‡¦', 'æ—¥æœ¬': 'ğŸ‡¯ğŸ‡µ', 'å¾·å›½': 'ğŸ‡©ğŸ‡ª',
    'å°åº¦': 'ğŸ‡®ğŸ‡³', 'ä¿„ç½—æ–¯': 'ğŸ‡·ğŸ‡º', 'éŸ©å›½': 'ğŸ‡°ğŸ‡·', 'æ¾³å¤§åˆ©äºš': 'ğŸ‡¦ğŸ‡º', 'æ„å¤§åˆ©': 'ğŸ‡®ğŸ‡¹',
 'æ–°åŠ å¡': 'ğŸ‡¸ğŸ‡¬',
}

CATEGORY_STRUCTURE = {
    "âœï¸AIå†™ä½œå·¥å…·":['å­¦æœ¯è®ºæ–‡å†™ä½œ', 'å…¬æ–‡/æ”¿åŠ¡å†™ä½œ', 'å°è¯´/æ–‡å­¦åˆ›ä½œ', 'è¥é”€/å•†ä¸šæ–‡æ¡ˆ', 'å¤šè¯­è¨€å†™ä½œè¾…åŠ©', 'ç»¼åˆå†…å®¹åˆ›ä½œ', 'é•¿æ–‡ç”Ÿæˆå·¥å…·', 'æ™ºèƒ½æ”¹å†™ä¼˜åŒ–', 'å‚ç›´é¢†åŸŸå·¥å…·', 'å›½é™…çŸ¥åå¹³å°'],
    "ğŸ–¼ï¸AIå›¾åƒç”Ÿæˆä¸åˆ›ä½œç±»å·¥å…·":["åŸºç¡€æ–‡ç”Ÿå›¾","å‚ç›´åœºæ™¯ç”Ÿæˆ","è§†é¢‘ç”Ÿæˆ"],
    "ğŸ–¼ï¸AIå›¾åƒç¼–è¾‘å¤„ç†ç±»å·¥å…·":["ä¸“ä¸šå›¾åƒå¤„ç†","æ™ºèƒ½ä¿®å¤","å¤šåŠŸèƒ½å¤„ç†å¥—ä»¶","AIå›¾ç‰‡èƒŒæ™¯ç§»é™¤å·¥å…·","AIå›¾ç‰‡ç‰©ä½“æŠ¹é™¤","AIå›¾åƒç¼–è¾‘"],
    "ğŸ–¼ï¸AIå›¾åƒç‰¹æ®Šã€ç‰¹è‰²å·¥èƒ½å·¥å…·":["äººåƒå¤„ç†","å•†ä¸šåº”ç”¨","è·¨æ¨¡æ€","å›¾åƒç¿»è¯‘","å®æ—¶ç”Ÿæˆ","ä¼ä¸šçº§è§£å†³æ–¹æ¡ˆ","AIå›¾ç‰‡æ— æŸæ”¾å¤§"],
    "ğŸ–¼ï¸AIå›¾åƒç¤¾åŒºä¸æ¨¡å‹å¹³å°":["æ¨¡å‹åˆ†äº«ç¤¾åŒº","åœ¨çº¿åˆ›ä½œç¤¾åŒº"],
    "ğŸ–¼ï¸AIå›¾åƒç§»åŠ¨ç«¯ä¼˜åŒ–":["è½»é‡çº§åº”ç”¨","ç§»åŠ¨ç«¯å…¶ä»–"],
    "ğŸ–¼ï¸AIå›¾ç‰‡ä¼˜åŒ–ä¿®å¤":["è€ç…§ç‰‡ä¿®å¤ä¸“é¡¹","æ‰¹é‡å¤„ç†å·¥å…·","æ™ºèƒ½ä¿®å›¾è½¯ä»¶","ä¸Šè‰²ä¸è°ƒè‰²å·¥å…·","å›¾ç‰‡å¢å¼ºä¸æ¸…æ™°åŒ–","é›†æˆç”Ÿæˆä¸ä¿®å›¾","ä¸“ä¸šé¢†åŸŸå·¥å…·"],
    "ğŸ¥AIè§†é¢‘å·¥å…·":["æ–‡ç”Ÿè§†é¢‘","çŸ­è§†é¢‘ç”Ÿæˆ","è§†é¢‘ç¼–è¾‘ä¸å¢å¼º","æ•°å­—äººè§†é¢‘ç”Ÿæˆ","å¤šæ¨¡æ€ç”Ÿæˆ","å•†ä¸šè§†é¢‘åˆ›ä½œ","å¼€æº/å¤§æ¨¡å‹å¹³å°","åŠ¨ç”»/åŠ¨æ¼«è§†é¢‘","å½±è§†çº§åˆ¶ä½œ","å›½é™…çŸ¥åå¹³å°ï¼ˆè§†é¢‘ï¼‰","ç‰¹è‰²åŠŸèƒ½"],
    "ğŸ“¡AIåŠå…¬å·¥å…·":["PPTæ™ºèƒ½ç”Ÿæˆ","å›¾è¡¨ä¸æ•°æ®å¯è§†åŒ–","æ–‡æ¡£æ™ºèƒ½å¤„ç†","å›½é™…çŸ¥åå¹³å°","æ•™å­¦ä¸“ç”¨","ç‰¹è‰²åŠŸèƒ½","æ•ˆç‡å¢å¼º","AIä¼šè®®å·¥å…·"],
    "ğŸ¨AIè®¾è®¡å·¥å…·":["ç”µå•†è®¾è®¡","å¹³é¢è®¾è®¡","UX/UIè®¾è®¡","3D/æ¨¡å‹è®¾è®¡","ç»¼åˆè®¾è®¡å¹³å°","AIå›¾åƒç¼–è¾‘","ä¸“ä¸šé¢†åŸŸ","å›½é™…çŸ¥åå¹³å°ï¼ˆè®¾è®¡ï¼‰"],
    "ğŸ’¬AIå¯¹è¯èŠå¤©":["é€šç”¨å‹æ™ºèƒ½åŠ©æ‰‹","è§’è‰²æ‰®æ¼”/è™šæ‹Ÿé™ªä¼´","ä¼ä¸šå¤§æ¨¡å‹äº§å“","å›½é™…çŸ¥åå¹³å°ï¼ˆå¯¹è¯èŠå¤©ï¼‰","å¤šæ¨¡æ€åŠ©æ‰‹",],
    "ğŸ’»AIç¼–ç¨‹å·¥å…·":["ä»£ç ç”Ÿæˆä¸è¡¥å…¨","ä»£ç æµ‹è¯•ä¸åˆ†æ","äº‘ç«¯ä¸åœ¨çº¿å¼€å‘","å‰ç«¯ä¸UIå¼€å‘", "å¼€æºä¸è‡ªæ‰˜ç®¡","ä¼ä¸šçº§è§£å†³æ–¹æ¡ˆï¼ˆç¼–ç¨‹ï¼‰","IDEé›†æˆ","æ™ºèƒ½å¼€å‘è¾…åŠ©","å‚ç›´é¢†åŸŸ","å›½é™…çŸ¥åå¹³å°ï¼ˆç¼–ç¨‹ï¼‰"],
    "ğŸ”AIæœç´¢å¼•æ“":["é€šç”¨ç»¼åˆæœç´¢","å‚ç›´é¢†åŸŸæœç´¢ã€å­¦æœ¯ç ”ç©¶ã€‘","å‚ç›´é¢†åŸŸæœç´¢ã€å•†ä¸šé‡‘èã€‘","å‚ç›´é¢†åŸŸæœç´¢ã€å¼€å‘è€…ä¸“ç”¨ã€‘","äº¤äº’æ¨¡å¼åˆ›æ–°","å¤šåª’ä½“æœç´¢","ç”Ÿæ€é›†æˆæœç´¢","åœºæ™¯åŒ–æœç´¢","æŠ€æœ¯æ¶æ„åˆ›æ–°","å›½é™…å¹³å°"],
    'ğŸµAIéŸ³é¢‘å·¥å…·':["æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰","è¯­éŸ³è½¬æ–‡å­—ï¼ˆSSTï¼‰","éŸ³ä¹ç”Ÿæˆå¹³å°","å£°éŸ³å…‹éš†ä¸å˜å£°","éŸ³é¢‘å¤„ç†ä¸ç¼–è¾‘","æ­Œå£°åˆæˆç³»ç»Ÿ","è¯­éŸ³äº¤äº’","å¼€æºä¸å¼€å‘è€…","å¤šæ¨¡æ€åˆ›æ–°å¹³å°","ä¼ä¸šçº§è§£å†³æ–¹æ¡ˆï¼ˆéŸ³é¢‘ï¼‰"],
    'ğŸ› ï¸AIå¼€å‘å¹³å°':["æ™ºèƒ½ä½“å¼€å‘å¹³å°","æ·±åº¦å­¦ä¹ æ¡†æ¶","æœºå™¨å­¦ä¹ åº“ä¸å·¥å…·","æ— ä»£ç /ä½ä»£ç å¹³å°","ä¼ä¸šçº§è§£å†³æ–¹æ¡ˆï¼ˆå¼€å‘å¹³å°ï¼‰","æ•°æ®æ ‡æ³¨ä¸å¤„ç†","è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰","è¾¹ç¼˜è®¡ç®—ä¸éƒ¨ç½²","å¼€å‘è€…ç¤¾åŒºä¸åä½œ","ç»¼åˆæœåŠ¡å¹³å°"],
    'âš™ï¸AIè®­ç»ƒæ¨¡å‹':["å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰","å¤šæ¨¡æ€å¤§æ¨¡å‹","å›¾åƒç”Ÿæˆæ¨¡å‹","è§†é¢‘ç”Ÿæˆæ¨¡å‹","ä»£ç ç”Ÿæˆæ¨¡å‹","å¼€æºæ¡†æ¶ä¸å·¥å…·","ä¼ä¸šçº§å¹³å°","æœ¬åœ°éƒ¨ç½²","è®­ç»ƒä¼˜åŒ–","æ¨¡å‹åº“ä¸ç¤¾åŒº","ä¸“é¡¹é¢†åŸŸæ¨¡å‹","å­¦æœ¯ç ”ç©¶é¡¹ç›®"],
    'ğŸ“‘AIå†…å®¹æ£€æµ‹':["é€šç”¨æ–‡æœ¬æ£€æµ‹","å­¦æœ¯ä¸“ç”¨æ£€æµ‹","å¤šè¯­ç§æ£€æµ‹","å›¾åƒæ£€æµ‹","åŸåˆ›æ€§åˆ†æ","GPTä¸“é¡¹æ£€æµ‹","ä¼ä¸šçº§è§£å†³æ–¹æ¡ˆï¼ˆæ£€æµ‹ï¼‰"],
    'ğŸŒAIè¯­è¨€ç¿»è¯‘':["é€šç”¨æ–‡æœ¬ç¿»è¯‘","å¤šè¯­è¨€æ”¯æŒ","ä¼ä¸šçº§è§£å†³æ–¹æ¡ˆï¼ˆç¿»è¯‘ï¼‰","å®æ—¶è¯­éŸ³ç¿»è¯‘","å¤šæ¨¡æ€ç¿»è¯‘","æµè§ˆå™¨æ’ä»¶","åŒå£°ä¼ è¯‘","ç‰¹è‰²åŠŸèƒ½"],
    'ğŸ›ï¸AIæ³•å¾‹åŠ©æ‰‹':["æ³•å¾‹çŸ¥è¯†æ£€ç´¢å¹³å°","æ³•å¾‹å’¨è¯¢ä¸å»ºè®®åŠ©æ‰‹", "åˆåŒç”Ÿæˆä¸ç®¡ç†", "å¼€æºæ³•å¾‹æ¨¡å‹ä¸æ¡†æ¶"],
    'ğŸ“¡AIæç¤ºæŒ‡ä»¤':["æç¤ºè¯ç”Ÿæˆä¸ä¼˜åŒ–","å‚ç›´é¢†åŸŸæç¤ºåº“","ç¤¾åŒºä¸å¸‚åœºå¹³å°", "å¼€æºæ¡†æ¶ä¸å¼€å‘è€…", "æ•™è‚²å­¦ä¹ èµ„æº", "æµè§ˆå™¨é›†æˆ","å¤šæ¨¡æ€æ”¯æŒ"],
    'ğŸ“¦AIæ¨¡å‹è¯„æµ‹':["ç»¼åˆèƒ½åŠ›è¯„æµ‹åŸºå‡†","ä¸­æ–‡ä¸“é¡¹æµ‹è¯„ä½“ç³»","å¤šæ¨¡æ€è¯„æµ‹å¹³å°","å‚ç›´é¢†åŸŸè¯„æµ‹åŸºå‡†","å¼€æºç¤¾åŒºæ’è¡Œæ¦œ","å­¦æœ¯æœºæ„è¯„æµ‹ä½“ç³»","è¯„æµ‹æ–¹æ³•è®ºåˆ›æ–°"],
    'ğŸ‘ï¸AIå­¦ä¹ ç½‘ç«™':["å­¦æœ¯æœºæ„è¯¾ç¨‹","ä¼ä¸šåŸ¹è®­ä½“ç³»","MOOCå¹³å°ä¸“åŒº","å¼€æºå­¦ä¹ ç¤¾åŒº","å®è·µå®è®­å¹³å°","é’å°‘å¹´æ•™è‚²ä¸“åŒº","é€šè¯†æ•™è‚²å¹³å°","å·¥å…·å‹å­¦ä¹ è¾…åŠ©","é˜…è¯»æå‡","å‚ç›´é¢†åŸŸã€æ•™è‚²ã€‘"],
}

COUNTRY_MAPPING = {
                'ä¸­å›½': ['china', 'cn', 'ä¸­å›½', 'ä¸­è¯', 'ä¸­å›½å¤§é™†'],
                'ç¾å›½': ['usa', 'us', 'america', 'ç¾å›½', 'ç¾åˆ©åš'],
                'æ—¥æœ¬': ['japan', 'jp', 'æ—¥æœ¬', 'æ—¥æœ¬å›½'],
                'éŸ©å›½': ['korea', 'kr', 'éŸ©å›½', 'å¤§éŸ©æ°‘å›½', 'korean'],
                'è‹±å›½': ['uk', 'gb', 'united kingdom', 'è‹±å›½', 'å¤§ä¸åˆ—é¢ ', 'è‹±ä¼¦'],
                'æ³•å›½': ['france', 'fr', 'æ³•å›½', 'æ³•å…°è¥¿'],
                'å¾·å›½': ['germany', 'de', 'å¾·å›½', 'å¾·æ„å¿—'],
                'æ„å¤§åˆ©': ['italy', 'it', 'æ„å¤§åˆ©', 'æ„å¤§åˆ©å…±å’Œå›½'],
                'åŠ æ‹¿å¤§': ['canada', 'ca', 'åŠ æ‹¿å¤§'],
                'æ¾³å¤§åˆ©äºš': ['australia', 'au', 'æ¾³å¤§åˆ©äºš'],
                'æ–°è¥¿å…°': ['new zealand', 'nz', 'æ–°è¥¿å…°'],
                'ç‘å£«': ['switzerland', 'ch', 'ç‘å£«', 'ç‘å£«è”é‚¦'],
                'è·å…°': ['netherlands', 'nl', 'è·å…°', 'å°¼å¾·å…°'],
                'æ¯”åˆ©æ—¶': ['belgium', 'be', 'æ¯”åˆ©æ—¶'],
                'å¥¥åœ°åˆ©': ['austria', 'at', 'å¥¥åœ°åˆ©'],
                'ç‘å…¸': ['sweden', 'se', 'ç‘å…¸'],
                'æŒªå¨': ['norway', 'no', 'æŒªå¨'],
                'ä¸¹éº¦': ['denmark', 'dk', 'ä¸¹éº¦'],
                'èŠ¬å…°': ['finland', 'fi', 'èŠ¬å…°'],
                'çˆ±å°”å…°': ['ireland', 'ie', 'çˆ±å°”å…°'],
                'å¢æ£®å ¡': ['luxembourg', '.lu', 'å¢æ£®å ¡'],
                'è¥¿ç­ç‰™': ['spain', '.es', 'è¥¿ç­ç‰™'],
                'è‘¡è„ç‰™': ['portugal', '.pt', 'è‘¡è„ç‰™'],
                'å¸Œè…Š': ['greece', '.gr', 'å¸Œè…Š'],
                'ä»¥è‰²åˆ—': ['israel', '.il', 'ä»¥è‰²åˆ—'],
                'æ–°åŠ å¡': ['singapore', '.sg', 'æ–°åŠ å¡'],
                'æ³¢å…°': ['poland', '.pl', 'æ³¢å…°'],
            }

# ================== åœ¨CATEGORY_STRUCTUREä¹‹åæ·»åŠ  ==================
BOOKMARK_CATEGORIES = {
    "å¸¸ç”¨å·¥å…·": ["AIåŠå…¬","AIè§†é¢‘","AIå›¾åƒ","AIç¼–ç¨‹","å·¥å…·å¤§å…¨"],
    "å¼€å‘èµ„æº": ["å‰ç«¯", "åç«¯", "æ•°æ®åº“", "äº‘æœåŠ¡","å¤§æ¨¡å‹è°ƒç”¨"],
    "å­¦ä¹ å¹³å°": ["å…¬å¼€è¯¾", "æŠ€æœ¯æ–‡æ¡£", "è¡Œä¸šæŠ¥å‘Š"],
    "è®¾è®¡èµ„æº": ["UIæ¨¡æ¿", "å›¾æ ‡åº“", "é…è‰²æ–¹æ¡ˆ"],
    "ç ”ç©¶æœºæ„": ["AIå®éªŒå®¤", "å¤§å­¦ç ”ç©¶", "åˆ›æ–°ä¸­å¿ƒ"]
}

# åœ¨å…¨å±€å¸¸é‡éƒ¨åˆ†æ–°å¢
NEWS_API_ENDPOINT = "https://newsapi.org/v2/everything"
NEWS_API_KEY = "c15bca5299c84e97be7f3c7fe3678fe8"  # å®é™…ä½¿ç”¨æ—¶éœ€æ›¿æ¢ä¸ºæœ‰æ•ˆAPIå¯†é’¥


# ================== é…ç½®ç±» ==================
class EnhancedConfig:
    MIN_POPULARITY = 0
    SERPER_API_KEY = 'e89573bc1ad5b0c3fa6b58bc1dd3fcc8b585bf6a'

class PathConfig:
    """ç»Ÿä¸€ç®¡ç†æ‰€æœ‰æ–‡ä»¶è·¯å¾„"""
    def __init__(self):
        self.BASE_DIR = Path(__file__).parent.parent
        self.DATA_DIR = Path(os.getenv("DATA_DIR", self.BASE_DIR / "data"))
        self.SECURITY_DIR = Path(os.getenv("SECURITY_DIR", self.BASE_DIR / "security"))
        self.LOG_DIR = Path(os.getenv("LOG_DIR", self.BASE_DIR / "logs"))

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.DATA_DIR.mkdir(parents=True, exist_ok=True)
        self.SECURITY_DIR.mkdir(parents=True, exist_ok=True)
        self.LOG_DIR.mkdir(parents=True, exist_ok=True)

    @property
    def excel_file(self):
        return self.DATA_DIR / "ai_tools_900+.xlsx"

    @property
    def bookmark_file(self):
        return self.DATA_DIR / "bookmarks.xlsx"

# ================== æ ¸å¿ƒåŠŸèƒ½ç±» ==================

class HybridClassifier:
    """æ··åˆåˆ†ç±»å™¨ï¼ˆBERT + è§„åˆ™å¼•æ“ï¼‰"""
    def __init__(self):
        # ä½¿ç”¨HuggingFaceå®˜æ–¹æ¨¡å‹åç§°
        self.bert_model = pipeline(
            'feature-extraction',
            model="bert-base-multilingual-uncased",
            tokenizer="bert-base-multilingual-uncased"
        )

        self.rule_engine = RuleBasedClassifier()
        self.ml_model = None

    def predict(self, name, description):
        # è§„åˆ™å¼•æ“ä¼˜å…ˆ
        rule_result = self.rule_engine.classify(name, description)
        if rule_result.confidence > 0.8:
            return rule_result.category

        # BERTæ¨¡å‹é¢„æµ‹
        text = f"{name}: {description}"[:500]
        bert_result = self.bert_model(text)
        top_category = max(bert_result, key=lambda x: x['score'])

        # ç½®ä¿¡åº¦æ£€æŸ¥
        if top_category['score'] > 0.7:
            return top_category['label']
        else:
            return self.ml_predict(name, description)

class RuleBasedClassifier:
    """å¢å¼ºå‹è§„åˆ™åˆ†ç±»å™¨"""

    def __init__(self):
        self.rules = CATEGORY_KEYWORDS

    def classify(self, name, desc):
        text = f"{name} {desc}".lower()
        scores = {}
        for cat, keywords in self.rules.items():
            scores[cat] = sum(1 for kw in keywords if kw in text)

        max_score = max(scores.values())
        if max_score > 0:
            best_cat = max(scores, key=scores.get)
            return ClassificationResult(
                category=best_cat,
                confidence=max_score / len(self.rules[best_cat])
            )
        return ClassificationResult('å…¶ä»–', 0.0)

# ================== å‡½æ•°å®šä¹‰é¡ºåº ==================
# 1. åŸºç¡€å·¥å…·å‡½æ•°
def standardize_country(raw_name, mapping):
    """è¿”å›ç®€ä½“ä¸­æ–‡å›½å®¶åç§°"""
    raw = str(raw_name).strip().lower()
    for cn_name, aliases in mapping.items():
        if any(alias in raw for alias in aliases):
            return cn_name
    return 'å…¶ä»–'  # ç¡®ä¿è¿”å›å­—ç¬¦ä¸²ç±»å‹

def preprocess_dates(df):
    """ç»Ÿä¸€å¤„ç†å¤šç§æ—¥æœŸæ ¼å¼ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    if 'LastUpdated' not in df.columns:
        return df

    # å¼ºåˆ¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶å¤„ç†ç©ºå€¼
    df['LastUpdated'] = (
        df['LastUpdated']
        .astype(str)
        .replace('nan', '')  # å¤„ç†pandasçš„NaNå­—ç¬¦ä¸²è¡¨ç¤º
        .replace('NaT', '')  # å¤„ç†æ—¶é—´ç©ºå€¼
        .fillna('')  # åŒé‡ä¿é™©
    )

    # ç§»é™¤æ—¶é—´éƒ¨åˆ†ï¼ˆå¢å¼ºæ­£åˆ™ï¼‰
    df['LastUpdated'] = (
        df['LastUpdated']
        .str.replace(
            r'\s*\d{1,2}:\d{2}:\d{2}(?:\.\d+)?\s*',  # åŒ¹é…æ‰€æœ‰æ—¶é—´æ ¼å¼
            '',
            regex=True
        )
    )

    # ç»Ÿä¸€åˆ†éš”ç¬¦ä¸º-
    df['LastUpdated'] = (
        df['LastUpdated']
        .str.replace(r'[/å¹´æœˆæ—¥]', '-', regex=True)  # åˆå¹¶æ›¿æ¢æ“ä½œ
        .str.replace(r'-+', '-', regex=True)  # æ ‡å‡†åŒ–åˆ†éš”ç¬¦
    )

    # ç²¾ç¡®æå–æ—¥æœŸéƒ¨åˆ†
    df['LastUpdated'] = df['LastUpdated'].str.extract(
        r'(\d{4}-\d{1,2}-\d{1,2})',
        expand=False
    )

    return df

def fill_missing_dates(df):
    """æ”¯æŒæ··åˆæ—¥æœŸæ ¼å¼çš„æ™ºèƒ½è§£æ"""
    df = preprocess_dates(df)

    # å®šä¹‰å¸¸è§æ—¥æœŸæ ¼å¼ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
    date_formats = [
        '%Y-%m-%d',  # ISOæ ¼å¼
        '%Y/%m/%d',  # æ–œæ æ ¼å¼
        '%Y%m%d',  # ç´§å‡‘æ ¼å¼
        '%Yå¹´%mæœˆ%dæ—¥',  # ä¸­æ–‡æ ¼å¼
        '%d-%b-%y'
    ]


    df['LastUpdated'] = pd.to_datetime(
        df['LastUpdated'],
        errors='coerce',  # è½¬æ¢å¤±è´¥è®¾ä¸º NaT
        format='mixed',  # è‡ªåŠ¨æ£€æµ‹æ ¼å¼ï¼ˆPandas 2.0+ ç‰¹æ€§ï¼‰
        dayfirst=False  # ä¸ä½¿ç”¨æ—¥ä¼˜å…ˆæ ¼å¼
    )

    # å¡«å……ç¼ºå¤±æ—¥æœŸä¸ºå½“å‰æ—¥æœŸï¼ˆæ— æ—¶åŒºï¼‰
    now = pd.Timestamp.now().floor('D')
    df['LastUpdated'] = df['LastUpdated'].fillna(now)

    return df

def clean_country_names(df):
    """å›½å®¶åç§°æ ‡å‡†åŒ–"""
    country_mapping = COUNTRY_MAPPING
    df['Country'] = df['Country'].apply(lambda x: standardize_country(x, country_mapping))
    return df

def validate_url(url):
    """URLæ ‡å‡†åŒ–å¤„ç†"""
    if pd.isna(url) or url in ['', 'æ— ', 'none']:
        return ''
    url = str(url).strip()
    if not url.startswith(('http://', 'https://')):
        return f'https://{url}'
    return url

def validate_urls(df):
    """æ‰¹é‡URLæ ‡å‡†åŒ–å¤„ç†"""
    df['URL'] = df['URL'].apply(validate_url)
    return df

# 3.ä¸šåŠ¡é€»è¾‘å‡½æ•°
def calculate_popularity(df):
    """ç›´æ¥è¯»å–åŸå§‹æµè¡Œåº¦å€¼"""
    df['Popularity'] = (
        df['Popularity']
        .astype(int)
        .clip(lower=EnhancedConfig.MIN_POPULARITY, upper=1000)
    )
    return df

def sanitize_text(text):
    """æ–‡æœ¬å®‰å…¨å¤„ç†"""
    return text.strip().replace('\x00', '')  # ç§»é™¤ç©ºå­—ç¬¦ç­‰ç‰¹æ®Šç¬¦å·

def self_healing_data(df):
    """æ•°æ®è‡ªæ„ˆåŠŸèƒ½ï¼ˆè‡ªåŠ¨ä¿®å¤å¸¸è§é—®é¢˜ï¼‰"""
    # ä¿®å¤åç§°ä¸­çš„å¤šä½™ç©ºæ ¼
    df['Name'] = df['Name'].str.replace(r'\s+', ' ', regex=True).str.strip()

    # è‡ªåŠ¨è¯†åˆ«å¼€æºå­—æ®µ
    df['Open Source'] = df.apply(
        lambda x: 'æ˜¯' if ('å¼€æº' in str(x['Description'])) else x['Open Source'],
        axis=1
    )
    return df
    print(df['LastUpdated'].dtype)

def calculate_trend(row):
    """å¢å¼ºè¶‹åŠ¿è®¡ç®—ï¼ˆç»“åˆæ—¶é—´å› ç´ ï¼‰"""
    base = row['Popularity']
    days_since_update = (datetime.datetime.now() - row['LastUpdated']).days

    # æ ¹æ®æ›´æ–°æ—¶é—´å’Œæµè¡Œåº¦ç»¼åˆåˆ¤æ–­
    if days_since_update <= 7:  # ä¸€å‘¨å†…æ›´æ–°
        if base > 700:
            return 'ğŸš€ çˆ†ç«æ–°æ˜Ÿ'
        elif base >= 500:
            return 'âœ¨ è¿‘æœŸçƒ­é—¨'
    else:
        if base > 800:
            return 'ğŸ† é•¿æœŸçƒ­é—¨'

    if base >= 600:
        return 'ğŸ“ˆ ä¸Šå‡è¶‹åŠ¿'
    elif base >= 400:
        return 'ğŸ†— ä¿æŒç¨³å®š'
    else:
        return 'â³ æ½œåŠ›å¾…æŒ–'

def validate_opensource(value):
    """å¼€æºå­—æ®µæ ‡å‡†åŒ–"""
    value = str(value).strip().lower()
    return 'æ˜¯' if value in ['æ˜¯', 'yes', 'y', 'true', 'å¼€æº'] else 'å¦'

# 4. åˆ†ç±»ç›¸å…³å‡½æ•° =
def classify_tool(name, description):
    """å‡çº§åçš„åˆ†ç±»å…¥å£"""
    classifier = HybridClassifier()
    return classifier.predict(name, description)

# 5. æ•°æ®è´¨é‡æ£€æŸ¥
def validate_row(row):
    """éªŒè¯å•è¡Œæ•°æ®æœ‰æ•ˆæ€§"""
    errors = []

    # æ£€æŸ¥å¿…å¡«å­—æ®µ
    if pd.isna(row['Name']):
        errors.append("åç§°ä¸èƒ½ä¸ºç©º")
    if pd.isna(row['Category']):
        errors.append("åˆ†ç±»ä¸èƒ½ä¸ºç©º")

    return errors if errors else None

def data_quality_check(df):
    """æ—¥æœŸè´¨é‡éªŒè¯"""
    errors = []

    # æ£€æŸ¥æ—¥æœŸæ˜¯å¦å…¨éƒ¨è§£ææˆåŠŸ
    if df['LastUpdated'].isna().any():
        bad_count = df['LastUpdated'].isna().sum()
        errors.append(f"{bad_count} æ¡æ—¥æœŸè§£æå¤±è´¥")

    # æ£€æŸ¥æ—¥æœŸèŒƒå›´åˆç†æ€§
    latest_date = df['LastUpdated'].max()
    if latest_date > pd.Timestamp.now() + pd.DateOffset(years=1):
        errors.append("å­˜åœ¨æœªæ¥è¶…è¿‡1å¹´çš„æ—¥æœŸ")

    return errors

@st.cache_data(ttl=3600, show_spinner="åŠ è½½æ•°æ®ä¸­...")
def load_data(path):
    try:
        df = pd.read_excel(path, sheet_name="Tools")
        df.columns = df.columns.str.title()  # æ–°å¢åˆ—åæ ‡å‡†åŒ–
        df = df.dropna(subset=['Name', 'Url'])  # æ³¨æ„åˆ—åæ”¹ä¸ºé¦–å­—æ¯å¤§å†™
        return preprocess_data(df)
    except Exception as e:
        logging.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return pd.DataFrame()

def preprocess_data(df):
    """æ•°æ®é¢„å¤„ç†æµæ°´çº¿"""
    # ç¡®ä¿åˆ—åç»Ÿä¸€ä¸ºé¦–å­—æ¯å¤§å†™
    required_columns = ['Name', 'Category', 'Country', 'Url', 'Popularity', 'Lastupdated']
    for col in required_columns:
        if col not in df.columns:
            df[col] = None

    # å¤„ç†å›½å®¶åˆ—
    df['Country'] = df['Country'].apply(lambda x: str(x).title())  # ç»Ÿä¸€å›½å®¶åˆ—æ ¼å¼
    df['Country'] = df['Country'].apply(lambda x: x if x in COUNTRY_FLAGS else 'å…¶ä»–')

    # å¤„ç†æ—¥æœŸåˆ—
    df['LastUpdated'] = pd.to_datetime(df['LastUpdated'], errors='coerce').fillna(pd.Timestamp.now())

    # å¤„ç†æµè¡Œåº¦
    df['Popularity'] = pd.to_numeric(df['Popularity'], errors='coerce')
    df['Popularity'] = df['Popularity'].fillna(50).astype(int).clip(0, 1000)

    # å¤„ç†åˆ†ç±»åˆ—
    if 'Category' not in df.columns:
        df['Category'] = 'æœªåˆ†ç±»'
    df['Category'] = df['Category'].str.title().fillna('æœªåˆ†ç±»')

    return df

def load_tool_data(excel_file):
    """åŠ è½½å·¥å…·æ•°æ®ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    categories = {}
    seen = set()  # æ·»åŠ åˆå§‹åŒ–
    try:
        # å®šä¹‰é¢„æœŸçš„åˆ—ååˆ—è¡¨
        expected_columns = [
            'Name', 'Category', 'Country', 'Company', 'Description',
            'URL', 'Open Source', 'Popularity', 'LastUpdated'
        ]
        # ========== è¯»å–æ•°æ® ==========
        # è¯»å–æ—¶é™åˆ¶åˆ—å¹¶éªŒè¯
        df = pd.read_excel(
            excel_file,
            sheet_name="Tools",
            usecols=expected_columns, # å…³é”®ä¿®æ”¹ï¼šå¼ºåˆ¶ä½¿ç”¨é¢„æœŸåˆ—
            header=0)
        # æ·»åŠ åˆ†ç±»å­—æ®µå¤„ç†
        if 'Category' not in df.columns:
            df['Category'] = 'æœªåˆ†ç±»'
        else:
            df['Category'] = df['Category'].str.strip().fillna('æœªåˆ†ç±»')
        # æ–°å¢ï¼šå¡«å……æ‰€æœ‰æ–‡æœ¬åˆ—çš„ç©ºå€¼ä¸ºç©ºå­—ç¬¦ä¸²
        text_columns = ['Name', 'Category', 'Country', 'Company', 'Description', 'URL']
        df[text_columns] = df[text_columns].fillna('')

        # ç¡®ä¿åˆ—å­˜åœ¨æ€§
        required_columns = ['Name', 'Popularity', 'LastUpdated']
        # éªŒè¯å…³é”®åˆ—æ•°æ®å®Œæ•´æ€§
        missing_data = df[required_columns].isna().any(axis=1)
        if missing_data.any():
            st.error(f"å‘ç° {missing_data.sum()} è¡Œç¼ºå¤±å…³é”®æ•°æ®")
            st.dataframe(df[missing_data][required_columns])
            df = df.dropna(subset=required_columns)

        missing_cols = [col for col in required_columns if col not in df.columns]
        if missing_cols:
            st.error(f"âŒ ç¼ºå°‘å¿…è¦åˆ—: {', '.join(missing_cols)}")
            return {}

        df = df.dropna(subset=['Popularity', 'LastUpdated'])
        # å¦‚æœæˆåŠŸè¯»å–æ•°æ®ï¼Œç»§ç»­è¿›è¡Œå¤„ç†
        if df.empty:
            st.warning("âš ï¸ å·¥å…·æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥Excelæ–‡ä»¶")
            return {}

        # 1. å¤„ç†ç¼ºå¤±å­—æ®µ
        required_columns = {
            'Popularity': 0,
            'LastUpdated': pd.Timestamp.now().floor('D'),
            'Category': None  # ç‰¹æ®Šå¤„ç†åˆ†ç±»å­—æ®µ
        }

        for col, default_val in required_columns.items():
            if col not in df.columns:
                df[col] = default_val if col != 'Category' else pd.NA
                if col != 'Category':  # åˆ†ç±»å­—æ®µéœ€è¦ç‰¹æ®Šå¤„ç†
                    st.warning(f"âš ï¸ æ£€æµ‹åˆ°ç¼ºå¤±å­—æ®µ '{col}'ï¼Œå·²è‡ªåŠ¨ç”Ÿæˆé»˜è®¤å€¼")

        # åº”ç”¨éªŒè¯
        validation_results = df.apply(validate_row, axis=1)
        if any(validation_results):
            st.error("å‘ç°æ•°æ®éªŒè¯é”™è¯¯ï¼š")
            for idx, errors in enumerate(validation_results):
                if errors:
                    st.write(f"ç¬¬ {idx + 2} è¡Œé”™è¯¯ï¼š{', '.join(errors)}")
            return {}
            # é¢„å¤„ç†é˜¶æ®µæ·»åŠ æ—¥æœŸæ¸…æ´—
        df = (df
              .pipe(clean_country_names)
              .pipe(fill_missing_dates)
              .pipe(validate_urls)
              .pipe(calculate_popularity)  # ä½¿ç”¨ç®€åŒ–åçš„è®¡ç®—
              .pipe(self_healing_data)
              )
        # åœ¨ load_tool_data ä¸­è°ƒç”¨
        errors = data_quality_check(df)
        if errors:
            st.error("âš ï¸ æ•°æ®è´¨é‡é—®é¢˜: " + ", ".join(errors))
            st.dataframe(df[df['LastUpdated'].isna()])  # å±•ç¤ºé”™è¯¯æ•°æ®

        # æ·»åŠ æ—¥æœŸæ ¼å¼éªŒè¯
        invalid_dates = df[df['LastUpdated'].isna()]
        if not invalid_dates.empty:
            st.error(f"å‘ç° {len(invalid_dates)} æ¡æ— æ•ˆæ—¥æœŸè®°å½•")
            st.dataframe(invalid_dates[['Name', 'LastUpdated']])
            df = df.dropna(subset=['LastUpdated'])


        # 3. è‡ªåŠ¨åˆ†ç±»è¡¥å…¨ï¼ˆåŸåŠŸèƒ½å¢å¼ºï¼‰
        df['Category'] = df.apply(
            lambda row: classify_tool(row['Name'], row['Description'])
            if pd.isna(row['Category']) else row['Category'],
            axis=1
        )
        # æ·»åŠ ç±»å‹æ£€æŸ¥
        if not pd.api.types.is_datetime64_ns_dtype(df['LastUpdated']):
            st.error("æ—¥æœŸåˆ—ç±»å‹è½¬æ¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼")
            return {}
        # ========== æ•°æ®æ ‡å‡†åŒ–å¤„ç† ==========
        for _, row in df.iterrows():
            # å­—æ®µæœ‰æ•ˆæ€§æ£€æŸ¥ï¼ˆå¢å¼ºç‰ˆï¼‰
            if any([
                pd.isna(row['Name']),
                pd.isna(row['Category']),
                pd.isna(row['URL'])
            ]):
                continue

            # æ•°æ®æ ‡å‡†åŒ–å¤„ç†
            item = {
                'name': str(row['Name']).strip(),
                'category': str(row['Category']).strip(),
                'url': validate_url(row['URL']),
                'description': sanitize_text(row.get('Description')),
                'country':standardize_country(str(row.get('Country', '')),mapping=COUNTRY_MAPPING),
                'open_source': validate_opensource(row.get('Open Source', 'å¦')),
                'company': str(row.get('Company', '')).strip(),
                'popularity': int(row.get('Popularity', 0)),
                'last_updated': row['LastUpdated'].to_pydatetime().replace(tzinfo=None),  # ç§»é™¤æ—¶åŒºä¿¡æ¯
                'trend': calculate_trend(row)

            }

            # é˜²æ­¢é‡å¤æ¡ç›®
            key = (item['name'], item['category'])
            if key in seen:
                continue
            seen.add(key)

            # æœ‰æ•ˆæ€§æœ€ç»ˆéªŒè¯
            if not all([item['name'], item['category'], item['url']]):
                continue

            # åˆ†ç±»å­˜å‚¨
            categories.setdefault(item['category'], []).append(item)
            item['last_updated'] = row['LastUpdated'].to_pydatetime().replace(tzinfo=None)

        return categories

    except FileNotFoundError:
        st.error("âŒ æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„")
        return {}
    except Exception as e:
        st.error(f"ğŸš¨ æ•°æ®åŠ è½½é”™è¯¯ï¼š{str(e)}")
        return {}

def load_tutorial_data(excel_file):
    """åŠ è½½æ•™ç¨‹æ•°æ®"""
    try:
        df = pd.read_excel(excel_file, sheet_name='Tutorials')
        tutorials = {}
        for _, row in df.iterrows():
            tool_name = row['RelatedTool']
            tutorial = {
                'id': row['TutorialID'],
                'title': row['Title'],
                'url': row['URL'],
                'type': row['Type'],
                'difficulty': row['DifficultyLevel'],
                'duration': row.get('Duration', ''),
                'rating': row.get('Rating', None),
                'language': row.get('Language', 'ä¸­æ–‡'),
                'tags': [t.strip() for t in str(row.get('Tags', '')).split(',')],
                'version': row.get('VersionCompatible', ''),
                'author': row.get('Author', '')
            }
            tutorials.setdefault(tool_name, []).append(tutorial)
        return tutorials
    except Exception as e:
        st.error(f"æ•™ç¨‹æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return {}

def save_all_data(excel_file, tools_data, tutorials_data):
    """ä¿å­˜æ‰€æœ‰æ•°æ®åˆ°Excel"""
    try:
        tools_rows = []
        for category, items in tools_data.items():
            for item in items:
                tools_rows.append({
                    'Name': item['name'],
                    'Category': category,
                    'Country': item['country'],
                    'Company': item.get('company', ''),
                    'Description': item['description'],
                    'URL': item['url'],
                    'Open Source': item['open_source']
                })
        tools_df = pd.DataFrame(tools_rows)

        tutorials_rows = []
        for tool_name, tutorials in tutorials_data.items():
            for tut in tutorials:
                tutorials_rows.append({
                    'TutorialID': tut['id'],
                    'RelatedTool': tool_name,
                    'Title': tut['title'],
                    'URL': tut['url'],
                    'Type': tut['type'],
                    'DifficultyLevel': tut['difficulty'],
                    'Duration': tut.get('duration', ''),
                    'Rating': tut.get('rating', None),
                    'Language': tut.get('language', 'ä¸­æ–‡'),
                    'Tags': ', '.join(tut.get('tags', [])),
                    'VersionCompatible': tut.get('version', ''),
                    'Author': tut.get('author', '')
                })
        tutorials_df = pd.DataFrame(tutorials_rows)

        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
            tools_df.to_excel(writer, sheet_name='Tools', index=False)
            tutorials_df.to_excel(writer, sheet_name='Tutorials', index=False)
        return True
    except Exception as e:
        st.error(f"ä¿å­˜å¤±è´¥ï¼š{str(e)}")
        return False
# 7. UIç»„ä»¶å‡½æ•°
def render_url(url):
    """æ ¹æ®URLç”Ÿæˆè¶…é“¾æ¥"""
    if url and url != 'æ— ':
        return f'<a href="{url}" class="link-btn" target="_blank">{url}</a>'
    else:
        return "<span>æ— å¯ç”¨é“¾æ¥</span>"

def render_tool_card(item):
    if not isinstance(item, dict):
        st.error(f"éæ³•æ•°æ®é¡¹ç±»å‹: {type(item)}")
        return

    country = item.get('country', 'Unknown')
    flag = COUNTRY_FLAGS.get(country, 'ğŸŒ')
    badge = "ğŸŸ¢ å¼€æº" if item.get('open_source') == 'æ˜¯' else "ğŸ”´ é—­æº"
    company_info = f" - å…¬å¸ï¼š{item.get('company', '')}" if item.get('company') else ""

    url = item.get('url', None)

    popularity = item.get('popularity', 500)

    trend = item.get('trend', '')

    html = f"""
     <div class="item-card">
         <div style="display:flex; align-items:start; gap:12px">
             <div style="flex:1">
                 <div style="display:flex; align-items:center; gap:8px; margin-bottom:8px">
                     <div style="font-size:1.1rem; font-weight:600">{item['name']}</div>
                     <div style="font-size:1.2em">{flag}</div>
                     <div style="margin-left:auto; display:flex; align-items:center; gap:6px">
                         <span style="font-size:0.8em; background:{'#e8f5e9' if item['open_source'] == 'æ˜¯' else '#ffebee'}; 
                             color:{'#2e7d32' if item['open_source'] == 'æ˜¯' else '#c62828'}; 
                             padding:2px 8px; border-radius:12px">
                             {'å¼€æº' if item['open_source'] == 'æ˜¯' else 'é—­æº'}
                         </span>
                     </div>
                 </div>
                 <div style="display:flex; align-items:center; gap:8px; margin-top:8px">
                     <a href="{url}" target="_blank" class="link-btn" style="font-size:0.9em">
                         ğŸ”— è®¿é—®å®˜ç½‘
                     </a>
                     <span class="popularity-badge">
                         ğŸ”¥ {popularity} Â· {trend}
                     </span>
                 </div>
             </div>
         </div>
         <div class="tooltip">
            <h4>å…¬å¸ - {item['company']}</h4>
            <h4>å›½å®¶ - {item['country']}</h4>
            <div class="tooltip-content">
                {item.get('description', 'æš‚æ— è¯¦ç»†æè¿°')}
                <div class="features">
                    <hr style="margin:8px 0">
                    ç½‘å€ - {item.get('url', 'æ— å¯ç”¨é“¾æ¥')}
                   <!-- ä¸»è¦åŠŸèƒ½ï¼š
                    {item.get('features', 'åŠŸèƒ½ä¿¡æ¯å¾…è¡¥å……')} -->
                </div>
            </div>
        </div>
    </div>
 </div>
"""
    st.markdown(html, unsafe_allow_html=True)

def render_tutorial_search(tutorials_data, all_tools):
    """å¢å¼ºç‰ˆæ•™ç¨‹æœç´¢ç»„ä»¶"""
    with st.expander("ğŸ” é«˜çº§æ•™ç¨‹æœç´¢", expanded=False):
        col1, col2, col3 = st.columns([3, 2, 2])
        with col1:
            search_term = st.text_input("è¾“å…¥å·¥å…·åç§°æˆ–å…³é”®è¯")
        with col2:
            difficulty = st.selectbox("éš¾åº¦ç­‰çº§", ["å…¨éƒ¨", "åˆçº§", "ä¸­çº§", "é«˜çº§"])
        with col3:
            tutorial_type = st.selectbox("æ•™ç¨‹ç±»å‹", ["å…¨éƒ¨", "è§†é¢‘æ•™ç¨‹", "æ–‡æ¡£æŒ‡å—", "å®æˆ˜æ¡ˆä¾‹", "ç¤¾åŒºè®¨è®º"])

        # æ™ºèƒ½æœç´¢ç®—æ³•
        results = []
        for tool_name, tutorials in tutorials_data.items():
            tool_match = any([
                not search_term,
                search_term.lower() in tool_name.lower(),
                search_term.lower() in ' '.join(all_tools.get(tool_name, {}).get('tags', [])).lower()
            ])

            if tool_match:
                for tutorial in tutorials:
                    content_match = any([
                        not search_term,
                        search_term.lower() in tutorial['title'].lower(),
                        search_term.lower() in ' '.join(tutorial['tags']).lower()
                    ])

                    type_match = (tutorial_type == "å…¨éƒ¨") or (tutorial['type'] == tutorial_type)
                    difficulty_match = (difficulty == "å…¨éƒ¨") or (tutorial['difficulty'] == difficulty)

                    if content_match and type_match and difficulty_match:
                        results.append({
                            'tool': tool_name,
                            **tutorial
                        })

        # ç»“æœå±•ç¤º
        if results:
            st.success(f"ğŸ‰ æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ•™ç¨‹")
            for result in results:
                badge_class = {
                    'è§†é¢‘æ•™ç¨‹': 'video-badge',
                    'æ–‡æ¡£æŒ‡å—': 'doc-badge',
                    'å®æˆ˜æ¡ˆä¾‹': 'case-badge',
                    'ç¤¾åŒºè®¨è®º': 'community-badge'
                }.get(result['type'], '')

                with st.container(border=True):
                    cols = st.columns([3, 1, 1, 1])
                    cols[0].markdown(
                        f"**[{result['title']}]({result['url']})**  \n"
                        f"<span class='tutorial-badge {badge_class}'>{result['type']}</span> "
                        f"<span style='font-size:0.9em;color:#666'>{result['tool']}</span>",
                        unsafe_allow_html=True
                    )
                    cols[1].write(f"**éš¾åº¦**  \n{result['difficulty']}")


                    if result.get('tags'):
                        tags_str = " ".join([f"#{t}" for t in result['tags']])
                        st.caption(f"æ ‡ç­¾ï¼š{tags_str}")
                    else:
                        st.info("""
                                    ğŸ“˜ æ¨èå­¦ä¹ è·¯å¾„ï¼š
                                    1. è®¿é—®[AIå­¦ä¹ ä¸­å¿ƒ - å´æ©è¾¾ã€Šæœºå™¨å­¦ä¹ ã€‹è¯¾ç¨‹](https://www.coursera.org/learn/machine-learning)
                                    2. åŠ å…¥æˆ‘ä»¬çš„[å¼€å‘è€…ç¤¾åŒº - TensorFlowè®ºå›](https://discuss.tensorflow.org/)
                                    3. æŸ¥çœ‹[æœ€æ–°å·¥å…·åŠ¨æ€ - Hugging Faceåšå®¢](https://huggingface.co/blog)
                                    4. è®¿é—®[DeepLearning.AIè¯¾ç¨‹å¹³å°](https://www.deelearning.ai)
                                    5. åŠ å…¥[PyTorchå¼€å‘è€…è®¨è®ºåŒº](https://discuss.pytorch.org)
                                    6. è·Ÿè¸ª[Google AIæœ€æ–°åŠ¨æ€](https://ai.google/blog)
                                    7. å­¦ä¹ [ææ²ã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‹](https://zh.d2l.ai)
                                    8. å‚ä¸[ApacheCNä¸­æ–‡ç¤¾åŒº](https://www.apachecn.org)
                                    9. å…³æ³¨[æœºå™¨ä¹‹å¿ƒAIæ–°é—»](https://www.jiqizhixin.com)
                                    """)

def load_model():
    """åŠ è½½å·²æœ‰æ¨¡å‹"""
    model_path = PathConfig().SECURITY_DIR / "text_classifier.joblib"
    if model_path.exists():
        return joblib.load(model_path)
    return None

# 10. æœç´¢å¼•æ“é›†æˆ
def real_time_search(query):
    """ä½¿ç”¨Serper APIè¿›è¡Œå…¨ç½‘æœç´¢"""
    url = "https://google.serper.dev/search"
    payload = {
        "q": f"{query} AIå·¥å…· æ•™ç¨‹ æœ€æ–°èµ„è®¯",
        "gl": "cn",
        "hl": "zh-cn",
        "num": 5
    }
    headers = {
        'X-API-KEY': EnhancedConfig.SERPER_API_KEY,
        'Content-Type': 'application/json'
    }

    try:
        response = requests.post(url, json=payload, headers=headers)
        results = response.json()
        return parse_serper_results(results)
    except Exception as e:
        st.error(f"æœç´¢å¤±è´¥ï¼š{str(e)}")
        return []

def parse_serper_results(data):
    """è§£ææœç´¢å¼•æ“ç»“æœ"""
    parsed = []
    for result in data.get('organic', [])[:5]:
        parsed.append({
            'title': result.get('title'),
            'url': result.get('link'),
            'snippet': result.get('snippet'),
            'date': detect_date(result.get('snippet', ''))
        })
    return parsed

def detect_date(text):
    """ä»æ–‡æœ¬ä¸­æå–æ—¥æœŸ"""
    try:
        dt = parse(text, fuzzy=True)
        return dt.strftime("%Y-%m-%d")
    except:
        return "è¿‘æœŸ"

def refresh_tools():
    st.session_state.show_tools = True
    st.rerun()

# ================== æ–°å¢å‡½æ•° ==================
def load_bookmark_data(excel_file):
    """åŠ è½½æ”¶è—æ•°æ®"""
    try:
        df = pd.read_excel(excel_file, sheet_name="Bookmarks")
        bookmarks = []
        # æ·»åŠ åˆ—åå…¼å®¹æ€§å¤„ç†
        column_mapping = {
            "æ ‡é¢˜": "title",
            "URL": "url",
            "åˆ†ç±»": "category",
            "æ ‡ç­¾": "tags",
            "å¤‡æ³¨": "notes",
            "æ·»åŠ æ—¶é—´": "add_date"
        }
        df = df.rename(columns={k: v for k, v in column_mapping.items() if k in df.columns})
        for _, row in df.iterrows():
            bookmarks.append({
                "title": row.get("title", ""),
                "url": row.get("url", ""),
                "category": row.get("category", "æœªåˆ†ç±»"),
                "tags": row.get("tags", "").split(",") if pd.notna(row.get("tags")) else [],
                "notes": row.get("notes", ""),
                "add_date": row.get("add_date", datetime.datetime.now().strftime("%Y-%m-%d"))
            })
        return bookmarks
    except Exception as e:
        st.error(f"æ”¶è—æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return []

def save_bookmark_data(excel_file, bookmarks):
    """ä¿å­˜æ”¶è—æ•°æ®ï¼ˆä¿®å¤ç‰ˆï¼‰"""
    try:
        # è½¬æ¢æ•°æ®æ—¶ä½¿ç”¨ä¸åŠ è½½æ—¶ä¸€è‡´çš„åˆ—å
        df = pd.DataFrame([{
            "æ ‡é¢˜": b["title"],
            "URL": b["url"],
            "åˆ†ç±»": b["category"],
            "æ ‡ç­¾": ",".join(b["tags"]),
            "å¤‡æ³¨": b["notes"],
            "æ·»åŠ æ—¶é—´": b["add_date"]
        } for b in bookmarks])

        # ä½¿ç”¨æ­£ç¡®çš„å†™å…¥æ¨¡å¼
        with pd.ExcelWriter(excel_file, engine='openpyxl', mode='w') as writer:
            df.to_excel(writer, sheet_name="Bookmarks", index=False)
        return True
    except Exception as e:
        st.error(f"æ”¶è—ä¿å­˜å¤±è´¥: {str(e)}")
        return False

# æ–°å¢çƒ­ç‚¹èµ„è®¯è·å–å‡½æ•°
@st.cache_data(ttl=3600, show_spinner="è·å–çƒ­ç‚¹èµ„è®¯ä¸­...")
def fetch_hot_news(query="AIæŠ€æœ¯ äººå·¥æ™ºèƒ½ å¤§æ¨¡å‹ DeepSeek OpenAI ChatGPT"):
    try:
        params = {
            "q": query,
            "sortBy": "popularity",
            "pageSize": 5,
            "language": "zh",
            "apiKey": NEWS_API_KEY
        }

        response = requests.get(NEWS_API_ENDPOINT, params=params)
        data = response.json()

        articles = data.get('articles', [])
        processed = []
        for article in articles[:5]:  # å–å‰5æ¡
            processed.append({
                "title": article.get('title', ''),
                "url": article.get('url', '#'),
                "source": article.get('source', {}).get('name', 'æœªçŸ¥æ¥æº'),
                "snippet": article.get('description', ''),
                "time": article.get('publishedAt', '')[:10]
            })
        return processed
    except Exception as e:
        st.error(f"çƒ­ç‚¹èµ„è®¯è·å–å¤±è´¥: {str(e)}")
        return [{
            "title": "AIæŠ€æœ¯æœ€æ–°çªç ´ï¼šå¤šæ¨¡æ€å¤§æ¨¡å‹å–å¾—é‡å¤§è¿›å±•",
            "url": "#",
            "source": "è™šæ‹Ÿæ–°é—»",
            "snippet": "è¿‘æ—¥ï¼Œå…¨çƒé¡¶å°–ç ”ç©¶å›¢é˜Ÿå®£å¸ƒåœ¨è·¨æ¨¡æ€ç†è§£é¢†åŸŸå–å¾—çªç ´æ€§è¿›å±•...",
            "time": datetime.date.today().strftime("%Y-%m-%d")
        }]

# 11. ä¸»ç¨‹åº
def main():
    st.set_page_config(
        page_title="AIå·¥å…·å¯¼èˆªä¸­å¿ƒ",
        layout="wide",
        menu_items={
            'Get Help': 'https://example.com/help',
            'Report a bug': "mailto:1134593154@qq.com",
        }
    )

    # æ ‡é¢˜ä¼˜åŒ–
    st.markdown("""
        <h1 class="header gradient-text">ğŸ¤– AIå·¥å…·å¯¼èˆªä¸­å¿ƒ</h1>
        <div style="text-align:center; margin-bottom:2rem">
            <div style="display:inline-block; background: #f0f4f8; padding:8px 20px; border-radius:20px">
                <span style="color:#666">æ•°æ®æ›´æ–°ï¼š2025å¹´2æœˆ</span>
                <span style="margin:0 10px">|</span>
                <span style="color:#666">ç‰ˆæœ¬ï¼š2.3 </span>
                <span style="margin:0 10px">|</span>
                <span style="color:#666">ä½œè€…ï¼šåˆ˜æ™“ä¼Ÿ</span>
            </div>
        </div>
        """, unsafe_allow_html=True)

    # ================== æ•°æ®åŠ è½½ ==================
    path_config = PathConfig()
    excel_file = path_config.excel_file

    try:
        tools_data = load_tool_data(excel_file)
        tutorials_data = load_tutorial_data(excel_file)
        all_tools = {item['name']: item for cat in tools_data.values() for item in cat}
        st.session_state.tutorials_data = tutorials_data
    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return


    # ================== ä¾§è¾¹æ ä¼˜åŒ– ==================
    with st.sidebar:
        st.markdown("""
        <div style="text-align:center; margin:1rem 0">
            <div style="font-size:1.2rem; color:#2c3e50; font-weight:600">ğŸ” å¯¼èˆªé¢æ¿</div>
            <div style="height:2px; background:linear-gradient(90deg, transparent 0%, #3498db 50%, transparent 100%); margin:0.5rem 0"></div>
        </div>
        """, unsafe_allow_html=True)

        # åˆ†ç±»é€‰æ‹©æ”¹ç”¨é€‰é¡¹å¡
        selected_main = st.selectbox(
            "é€‰æ‹©ä¸»åˆ†ç±»",
            options=list(CATEGORY_STRUCTURE.keys()),
            index=0,
            format_func=lambda x: x.split(' ')[0]  # ä»…æ˜¾ç¤ºå›¾æ ‡å’Œåç§°
        )

        # å­åˆ†ç±»é€‰æ‹©ä¼˜åŒ–
        sub_categories = CATEGORY_STRUCTURE[selected_main]
        selected_sub = st.selectbox(
            f"é€‰æ‹©{selected_main.split(' ')[0]}å­ç±»",
            options=sub_categories,
            index=0,
            help="è¯·é€‰æ‹©å…·ä½“çš„å·¥å…·å­åˆ†ç±»"
        )


        st.header("â­ æˆ‘çš„çŸ¥è¯†å®åº“")

        # åŠ è½½æ”¶è—æ•°æ®
        if 'bookmarks' not in st.session_state:
            st.session_state.bookmarks = load_bookmark_data(path_config.bookmark_file)

        # æœç´¢å’Œç­›é€‰
        col1, col2 = st.columns([3, 2])
        search_term = col1.text_input("æœç´¢æ”¶è—å†…å®¹")
        filter_category = col2.selectbox("ç­›é€‰åˆ†ç±»", ["å…¨éƒ¨"] + list(BOOKMARK_CATEGORIES.keys()))

        # å±•ç¤ºæ”¶è—
        filtered = [
            b for b in st.session_state.bookmarks
            if (not search_term or search_term in b["title"]) and
               (filter_category == "å…¨éƒ¨" or b["category"] == filter_category)
        ]

        if filtered:
            for b in filtered:
                with st.expander(f"{b['title']} ({b['category']})", expanded=False):
                    cols = st.columns([3, 1])
                    cols[0].markdown(f"ğŸ”— [{b['url']}]({b['url']})")
                    cols[1].markdown(f"**æ·»åŠ æ—¶é—´**: {b['add_date']}")

                    if b["tags"]:
                        st.markdown(f"**æ ‡ç­¾**: {' '.join([f'ğŸ·ï¸{t}' for t in b['tags']])}")

                    if b["notes"]:
                        st.markdown(f"**å¤‡æ³¨**: {b['notes']}")

                    if st.button("åˆ é™¤", key=f"del_{b['url']}"):
                        st.session_state.bookmarks = [bm for bm in st.session_state.bookmarks
                                                      if bm['url'] != b['url']]
                        save_bookmark_data(path_config.bookmark_file, st.session_state.bookmarks)
                        st.rerun()
        else:
            st.info("æš‚æœªæ”¶è—ä»»ä½•å†…å®¹ï¼Œå¿«å»å‘ç°ç²¾å½©èµ„æºå§ï¼")
        # ç­›é€‰æ¡ä»¶åˆ†ç»„
        with st.expander("âš™ï¸ é«˜çº§ç­›é€‰", expanded=False):
            min_popularity = st.slider(
                "æœ€ä½æµè¡Œåº¦", 0, 1000, 300,
                help="è¿‡æ»¤æµè¡Œåº¦ä½äºè¯¥å€¼çš„å·¥å…·"
            )

            country_filter = st.multiselect(
                "å›½å®¶/åœ°åŒºç­›é€‰",
                options=list(COUNTRY_FLAGS.keys()),
                default=[],
                format_func=lambda x: f"{COUNTRY_FLAGS.get(x, 'ğŸŒ')} {x}"
            )

            st.divider()
    # ================== ä¸»å†…å®¹åŒºåŸŸ ==================
    try:
        # æ˜¾ç¤ºå½“å‰åˆ†ç±»æ ‡é¢˜
        st.subheader(f"{selected_main} - {selected_sub}")

        # è·å–ç­›é€‰åçš„æ•°æ®
        filtered_items = [
            item for item in tools_data.get(selected_sub, [])
            if item['popularity'] >= min_popularity
               and (not country_filter or item['country'] in country_filter)
        ]

        cols = st.columns(3)
        stats_style = """
            background: white;
            padding: 2rem;
            border-radius: 16px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.08);
            min-height: 160px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;  # æ–°å¢æ°´å¹³å±…ä¸­
            transition: transform 0.2s ease;  # æ·»åŠ æ‚¬åœåŠ¨ç”»
            border: 1px solid #f0f0f0;  # æ·»åŠ æŸ”å’Œè¾¹æ¡†
        """

        # ä¸ºæ‰€æœ‰åˆ—æ·»åŠ ç»Ÿä¸€æ‚¬åœæ•ˆæœ
        hover_style = """
            <style>
                div[data-testid="stVerticalBlock"] > div > div > div:hover {
                    transform: translateY(-5px);
                    box-shadow: 0 6px 16px rgba(0,0,0,0.12);
                }
            </style>
        """
        st.markdown(hover_style, unsafe_allow_html=True)

        with cols[0]:
            st.markdown(f"""
                <div style="{stats_style}">
                    <div style="color:#666; font-size:0.95rem; margin-bottom:8px">ğŸ“¦ å½“å‰åˆ†ç±»å·¥å…·æ•°</div>
                    <div style="font-size:2rem; color:#2a3f5f; font-weight:800">{len(filtered_items)}</div>
                </div>
            """, unsafe_allow_html=True)

        with cols[1]:
            st.markdown(f"""
                <div style="{stats_style}">
                    <div style="color:#666; font-size:0.95rem; margin-bottom:8px">ğŸ“ˆ å¹³å‡æµè¡Œåº¦</div>
                    <div style="font-size:2rem; color:#2a3f5f; font-weight:800">
                        {int(np.mean([i['popularity'] for i in filtered_items])) if filtered_items else 0}
                    </div>
                </div>
            """, unsafe_allow_html=True)

        with cols[2]:
            countries = [i['country'] for i in filtered_items]
            st.markdown(f"""
                <div style="{stats_style}">
                    <div style="color:#666; font-size:0.95rem; margin-bottom:8px">ğŸŒ ä¸»è¦å›½å®¶</div>
                    <div style="font-size:2rem; color:#2a3f5f; font-weight:800">
                        {max(set(countries), key=countries.count) if countries else "æ— "}
                    </div>
                </div>
            """, unsafe_allow_html=True)

        # æ˜¾ç¤ºå·¥å…·å¡ç‰‡
        if filtered_items:
            cols = st.columns(2)
            col_idx = 0
            for item in filtered_items:
                with cols[col_idx]:
                    render_tool_card(item)
                col_idx = 1 - col_idx  # åˆ‡æ¢åˆ—
        else:
            st.markdown("""
              <div style="text-align:center; padding:3rem; background:white; border-radius:12px">
                  <div style="font-size:1.2rem; color:#666; margin-bottom:1rem">ğŸ˜ æœªæ‰¾åˆ°åŒ¹é…å·¥å…·</div>
                  <div style="color:#888">å»ºè®®å°è¯•è°ƒæ•´ç­›é€‰æ¡ä»¶æˆ–æŸ¥çœ‹å…¶ä»–åˆ†ç±»</div>
              </div>
              """, unsafe_allow_html=True)

        # ================== æ•™ç¨‹æœç´¢åŒºåŸŸ ==================
        with st.expander("ğŸ“šæœ¬åœ°å·¥å…·+æ•™ç¨‹æœç´¢æ ", expanded=False):
            st.subheader("ğŸ” å¿«é€Ÿæœç´¢")

            # å·¥å…·æœç´¢åŠŸèƒ½æ¨¡å—
            def search_tools(search_term, search_field='name'):
                return [
                    item for cat in tools_data.values() for item in cat
                    if search_term.lower() in item[search_field].lower()
                ]

            # åŒåˆ—å¸ƒå±€æ”¹è¿›ç‰ˆ
            col_search1, col_search2 = st.columns(2)

            with col_search1:
                # å·¥å…·åç§°æœç´¢
                search_term = st.text_input("è¾“å…¥å·¥å…·åç§°å…³é”®è¯",
                                            placeholder="ä¾‹å¦‚ï¼šå›¾åƒè¯†åˆ«",
                                            key="name_search")
                if search_term:
                    name_results = search_tools(search_term, 'name')
                    if name_results:
                        st.success(f"åç§°åŒ¹é…ï¼šæ‰¾åˆ° {len(name_results)} ä¸ªå·¥å…·")
                        for item in name_results:
                            render_tool_card(item)
                    else:
                        st.info("âš ï¸ æœªæ‰¾åˆ°åç§°åŒ¹é…çš„å·¥å…·")

            with col_search2:
                # åŠŸèƒ½æè¿°æœç´¢
                search_term_function = st.text_input("è¾“å…¥åŠŸèƒ½å…³é”®è¯",
                                                     placeholder="ä¾‹å¦‚ï¼šèƒŒæ™¯è™šåŒ–",
                                                     key="func_search")
                if search_term_function:
                    func_results = search_tools(search_term_function, 'description')
                    if func_results:
                        st.success(f"åŠŸèƒ½åŒ¹é…ï¼šæ‰¾åˆ° {len(func_results)} ä¸ªå·¥å…·")
                        for item in func_results:
                            render_tool_card(item)
                    else:
                        st.info("âš ï¸ æœªæ‰¾åˆ°åŠŸèƒ½åŒ¹é…çš„å·¥å…·")

            # æ•™ç¨‹æœç´¢æ¨¡å—
            st.divider()
            st.subheader("ğŸ“ æ‰‹æŠŠæ‰‹æ•™ç¨‹æœç´¢")

            # æ”¹è¿›çš„æ•™ç¨‹æœç´¢é€»è¾‘
            tutorial_search = st.text_input("è¾“å…¥AIå·¥å…·åç§°æŸ¥æ‰¾æ•™ç¨‹",
                                            placeholder="ä¾‹å¦‚ï¼šPhotoshop AI",
                                            key='tutorial_search')

            if tutorial_search:
                matched_tutorials = []
                for tool_name, tutorial_list in tutorials_data.items():
                    # å¤„ç†ä¸åŒçš„æ•°æ®ç»“æ„æƒ…å†µ
                    if isinstance(tutorial_list, list) and len(tutorial_list) > 0:
                        if tutorial_search.lower() in tool_name.lower():
                            for tutorial in tutorial_list:
                                matched_tutorials.append((
                                    tool_name,
                                    tutorial.get('url', '#'),
                                    tutorial.get('source', 'æœªçŸ¥æ¥æº')
                                ))

                if matched_tutorials:
                    st.success(f"ğŸ” æ‰¾åˆ° {len(matched_tutorials)} ä¸ªç›¸å…³æ•™ç¨‹")
                    for name, url, source in matched_tutorials:
                        # ä½¿ç”¨streamlitåŸç”Ÿæ ·å¼
                        with st.container(border=True):
                            st.markdown(f"""
                            **{name}**  
                            ğŸ“š æ•™ç¨‹æ¥æºï¼š{source}  
                            ğŸ”— [ç‚¹å‡»æŸ¥çœ‹å®Œæ•´æ•™ç¨‹]({url})
                            """)
                else:
                    # ä¼˜åŒ–åçš„å­¦ä¹ èµ„æºæ¨è
                    st.info("""
                    ğŸ“˜ æ¨èå­¦ä¹ è·¯å¾„ï¼š
                    1. [æœºå™¨å­¦ä¹ åŸºç¡€ - å´æ©è¾¾ Coursera è¯¾ç¨‹](https://www.coursera.org/learn/machine-learning)
                    2. [æ·±åº¦å­¦ä¹ å®æˆ˜ - Fast.ai è¯¾ç¨‹](https://www.fast.ai)
                    3. [è‡ªç„¶è¯­è¨€å¤„ç† - Hugging Face æ•™ç¨‹](https://huggingface.co/learn)
                    4. [è®¡ç®—æœºè§†è§‰ - PyTorch å®˜æ–¹æ•™ç¨‹](https://pytorch.org/tutorials/)
                    5. åŠ å…¥æˆ‘ä»¬çš„[å¼€å‘è€…ç¤¾åŒº - TensorFlowè®ºå›](https://discuss.tensorflow.org/)
                    6. æŸ¥çœ‹[æœ€æ–°å·¥å…·åŠ¨æ€ - Hugging Faceåšå®¢](https://huggingface.co/blog)
                    7. è®¿é—®[DeepLearning.AIè¯¾ç¨‹å¹³å°](https://www.deelearning.ai)
                    8. åŠ å…¥[PyTorchå¼€å‘è€…è®¨è®ºåŒº](https://discuss.pytorch.org)
                    9. è·Ÿè¸ª[Google AIæœ€æ–°åŠ¨æ€](https://ai.google/blog)
                    10. å­¦ä¹ [ææ²ã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‹](https://zh.d2l.ai)
                    11. å‚ä¸[ApacheCNä¸­æ–‡ç¤¾åŒº](https://www.apachecn.org)
                    12. å…³æ³¨[æœºå™¨ä¹‹å¿ƒAIæ–°é—»](https://www.jiqizhixin.com)
                    """)
        with st.expander("ğŸŒ å…¨ç½‘AIå·¥å…·æœç´¢", expanded=False):
            search_query = st.text_input("è¾“å…¥æœç´¢å…³é”®è¯ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰",
                                         key="web_search",
                                         help="æœç´¢æœ€æ–°AIå·¥å…·èµ„è®¯å’Œæ•™ç¨‹")

            if search_query:
                with st.spinner('æ­£åœ¨æœç´¢å…¨ç½‘æœ€æ–°èµ„è®¯...'):
                    # æ‰§è¡Œå®æ—¶æœç´¢
                    results = real_time_search(search_query)

                if results:
                    st.success(f"æ‰¾åˆ° {len(results)} æ¡ç›¸å…³ç»“æœ")
                    for idx, item in enumerate(results[:5], 1):  # æ˜¾ç¤ºå‰3æ¡ç»“æœ
                        st.markdown(f"""
                                         <div class="item-card">
                                             <b>{idx}. {item['title']}</b>
                                             <div class="tooltip">
                                                 ğŸ“… {item['date']}
                                                 <span class="tooltiptext">
                                                     {item['snippet']}
                                                 </span>
                                             </div>
                                             <div style="margin-top:8px;">
                                                 <a href="{item['url']}" class="link-btn" target="_blank">æŸ¥çœ‹è¯¦æƒ…</a>
                                             </div>
                                         </div>
                                         """, unsafe_allow_html=True)
                else:
                    st.info("""
                                     ğŸ’¡ æœªæ‰¾åˆ°ç›¸å…³ç»“æœï¼Œå»ºè®®ï¼š
                                     1. å°è¯•ä¸åŒå…³é”®è¯ç»„åˆ
                                     2. æŸ¥çœ‹[çƒ­é—¨å·¥å…·æ¦œå•](#)
                                     3. è®¿é—®[AIæ–°é—»èšåˆç«™](#)
                                     """)
        st.markdown(STYLE, unsafe_allow_html=True)
        render_tutorial_search(tutorials_data, all_tools)
        # ================== æ–°å¢çƒ­ç‚¹èµ„è®¯å…¬å‘Šæ  ==================
        with st.expander("ğŸ“° ç‚¹å‡»å±•å¼€å®æ—¶çƒ­ç‚¹èµ„è®¯", expanded=False):
            st.markdown("""
             <div class="news-ticker">
                 <div class="news-header">ğŸ”¥ çƒ­ç‚¹èµ„è®¯</div>
                 <div class="news-marquee">
             """, unsafe_allow_html=True)

            hot_news = fetch_hot_news()
            for news in hot_news:
                st.markdown(f"""
                     <div class="news-card">
                         <div class="news-title">{news['title']}</div>
                         <div class="news-source">æ¥æºï¼š{news['source']} â€¢ {news['time']}</div>
                         <div class="news-snippet">{news['snippet']}</div>
                         <a href="{news['url']}" target="_blank" class="link-btn" style="font-size:0.8em">é˜…è¯»å…¨æ–‡ â†’</a>
                     </div>
                 """, unsafe_allow_html=True)
    except KeyError as e:
        st.error(f"åˆ†ç±»æ•°æ®é”™è¯¯: {str(e)}")

if __name__ == '__main__':
    main()